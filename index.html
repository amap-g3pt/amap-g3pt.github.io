<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VAT</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    

    /* Ensure teaser section is responsive */
    .teaser-image {
      width: 100%;
      height: auto;
    }
    .method-image-img-small {
  max-width: 80%;   /* 图片的最大宽度设为容器宽度的 80% */
  height: auto;     /* 保持图片的纵横比 */
  margin: 0 auto;   /* 居中显示 */
  display: block;   /* 使图片成为块级元素 */
}
.method-image-img-small-small {
  max-width: 50%;   /* 图片的最大宽度设为容器宽度的 80% */
  height: auto;     /* 保持图片的纵横比 */
  margin: 0 auto;   /* 居中显示 */
  display: block;   /* 使图片成为块级元素 */
}
  </style>
</head>
<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              G3PT: Unleash the Power of Autoregressive Modeling in 3D Generation via Cross-Scale Querying Transformer
            </h1>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.02202"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.02202"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <!-- Code Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/sparse-mvs-2/VAT"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span> -->
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="far fa-images"></i>
                    </span> -->
                    <!-- <span>Data</span> -->
                    </a>
              </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

 
  <section class="hero teaser"></section>
    <div class="container">
      <div class="hero-body">
        <img id="teaser-image" src="./static/images/Fig_pipeline.png" alt="Teaser Image" class="teaser-image">
        <p class="is-size-9" style="line-height: 1.6; color: #555;">
          <span class="dnerf" style="font-weight: bold; font-style: italic;">Abstract:</span> Autoregressive transformers have revolutionized generative models 
          in language processing and shown substantial promise in image and video generation. However, these models face significant challenges 
          when extended to 3D generation tasks due to their reliance on next-token prediction to learn token sequences, which is incompatible 
          with the unordered nature of 3D data. Instead of imposing an artificial order on 3D data, in this paper, 
          we introduce G3PT -- a scalable, coarse-to-fine 3D native generative model with cross-scale vector quantization and 
          cross-scale autoregressive modeling. The key is to map point-based 3D data into discrete tokens with different levels of detail, 
          naturally establishing a sequential relationship across a variety of scales suitable for autoregressive modeling. 
          Remarkably, our method connects tokens globally across different levels of detail without manually specified ordering. 
          Benefiting from this approach, G3PT features a versatile 3D generation pipeline that effortlessly supports the generation of 
          3D shapes under diverse conditional modalities. Extensive experiments demonstrate that G3PT achieves superior 3D generation quality 
          and generalization ability compared to previous baselines. Most importantly, for the first time in 3D generation, 
          scaling up G3PT reveals distinct power-law scaling behaviors.
        </p>
      </div>
    </div>
  </section>
 
  
  <section class="hero teaser">
    <div class="container">
      <div class="hero-body">
        <img id="teaser-image" src="./static/images/Fig_CVQ.png" alt="Teaser Image" class="teaser-image">
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Comparison of multi-scale vector quantization approaches.</span> (a) The quantization approach used in VAR 
          relies on average pooling and bilinear upsampling, which are not suitable for unordered data. 
          (b) Our Cross-scale Vector Quantization (CVQ) overcomes this limitation with CQT, which employs a set of cross-scale learnable 
          queries to globally "downsample" and "upsample" the unordered input feature with cross-attention. 
          Specifically, a set of "downsample" learnable queries "pool" the input feature into token vectors of decreased length 
          at each scale, effectively forming a level-of-detail tokenization. These cross-scale token vectors are then "upsampled" 
          to the original scale for residual quantization, with another set of "upsample" learnable queries. 
        </h2>
      </div>
    </div>
  </section>


<section class="hero teaser">
  <div class="hero-body">
    <div class="container">
      <div class="method-module">
        <h2 class="title is-2 method-title" style="text-align: center;"> </h2>

        <h2 class="title is-2 method-title" style="text-align: center;">Two-stage training</h2>

        <!-- Image Section -->
        <div class="method-image">
          <img src="./static/images/pic_pipeline.jpg" alt="Methodology Image" class="method-image-img">
        </div>

        <!-- Text Section -->
        <div class="method-description">
          <p class="is-size-9">
            (a) VAT comprises the 3D input features into a smaller 1D sequence of latent tokens. The encoder's output retains only the latent tokens, resulting in a compact 1D latent representation that preserves the original information.
Next, VVQ maps the 1D latent onto a Gaussian distribution, where quantization is applied residually across scales. This process allows tokens to self-organize into distinct subspaces within the same Gaussian distribution.
Following vector quantization, the triplane decoder recovers the output features based on the discrete token maps, and a triplane-based convolutional neural network, combined with an MLP, upsamples the low-resolution features into a high-resolution 3D occupancy grid.
          </p>
          <p class="is-size-9">
            (b) At the second stage, we train the Next-Scale Autoregressive Transformer on discrete tokens. Here, discrete tokens generated by VAT are used as supervised signal for a decoder-only transformer trained for next-scale prediction. The model is conditioned on 
            image and text features with a causal attention mask trained by cross-entropy loss.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="hero-body">
    <div class="container">
      <div class="method-module">
        
        <h2 class="title is-3 method-title" style="text-align: center;">Scaling law with network parameters N </h2>
        <!-- Image Section -->
        <div class="method-image">
          <img src="./static/images/Fig_scaling.png" alt="Methodology Image" class="method-image-img-small-small">
        </div>
        
        <h2 class="title is-2 method-title" style="text-align: center;"> </h2>
        

        <h2 class="title is-2 method-title" style="text-align: center;">3D Generation Comparision</h2>

        <!-- Image Section -->
        <div class="method-image">
          <img src="./static/images/fig_wild_compare.jpg" alt="Methodology Image" class="method-image-img">
        </div>

        <!-- Text Section -->
        <div class="method-description">
          <p class="is-size-9" style="margin-bottom: 40px;">
            Comparision of state-of-the art 3D generation methods using in-the-wild images. Note that the commercial software displayed on the left may expand thousands of their own data for training, whereas our model is only trained on the Objaverse dataset.
          </p>
        </div>
        
        <div class="method-description"></div>
          <p class="is-size-9">
            
          </p>
        </div>
        <div class="method-image">
          <img src="./static/images/table_gen.png" alt="Methodology Image" class="method-image-img-small">
        </div>

        <!-- Text Section -->
        <div class="method-description">
          <p class="is-size-9" style="text-align: center;">
            Quantitative comparison of state-of-the-art 3D generation methods.
          </p>
          
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="hero-body">
    <div class="container">
      <div class="method-module">
        <h2 class="title is-2 method-title" style="text-align: center;"> </h2>

        <h2 class="title is-2 method-title" style="text-align: center;">Necessity of VVQ</h2>

        <!-- Image Section -->
        <div class="method-image">
          <img src="./static/images/compare_tab.png" alt="Methodology Image" class="method-image-img-small-small">
        </div>

        <!-- Text Section -->
        <div class="method-description" style="margin-bottom: 40px;">
          <p class="is-size-9">
            Reconstruction results with varying numbers of tokens, with and without in-context token compression (Comp.) and Variational Vector Quantization (VVQ).
            By incorporating VVQ, our VAT achieves the best balance between reconstruction accuracy and cross-scale consistency.
          </p>
        </div>
        
        <div class="method-description"></div>
          <p class="is-size-9">
            
          </p>
        </div>
        <div class="method-image">
          <img src="./static/images/fig_supp_multiscale.jpg" alt="Methodology Image" class="method-image-img">
        </div>

        <!-- Text Section -->
        <div class="method-description">
          <p class="is-size-9" style="text-align: center;">
            Visualization of reconstructed mesh from different scales of tokens, with and without VVQ.
          </p>
          
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
     
      <h1 class="title is-3 publication-title">
        512-Byte code can represent delicated geometry (2000× compression):
      </h1>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_5.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_6.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_8.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_9.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_10.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_11.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_13.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_14.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_15.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_16.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_17.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_18.mp4"
                    type="video/mp4">
          </video>
        </div>
        
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <h1 class="title is-3 publication-title">
        Results of 3D generation conditioned on images:
      </h1>
      <!-- Carousel Container with Image and Video Modules -->
      <div id="results-carousel" class="carousel results-carousel">
        
        <!-- Image Module 1 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_0.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_0.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 2 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_1.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_1.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 3 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_2.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_2.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 4 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_3.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_3.mp4" type="video/mp4">
          </video>
        </div>

         <!-- Image Module 4 -->
         <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_4.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_4.mp4" type="video/mp4">
          </video>
        </div>

      
        
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">

      <!-- Carousel Container with Image and Video Modules -->
      <div id="results-carousel" class="carousel results-carousel">
        
        <!-- Image Module 1 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_7.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_7.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 2 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_8.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_8.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 3 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_9.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_9.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 4 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_6.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_6.mp4" type="video/mp4">
          </video>
        </div>

         <!-- Image Module 4 -->
         <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_5.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_5.mp4" type="video/mp4">
          </video>
        </div>

      
        
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small"></section>
  <div class="hero-body">
    <div class="container">
      <h1 class="title is-3 publication-title">
        Mesh visualization with generated textures:
      </h1>
      <!-- Carousel Container with Image and Video Modules -->
      <div id="results-carousel" class="carousel results-carousel">
        
        <!-- Image Module 1 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_texture/recon_0.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_texture/recon_0.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 2 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_texture/recon_2.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_texture/recon_2.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 3 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_texture/recon_3.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_texture/recon_3.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 4 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_texture/recon_4.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_texture/recon_4.mp4" type="video/mp4">
          </video>
        </div>


       <!-- Image Module 4 -->
       <div class="item item-steve">
        <img src="./static/videos_jinzhi/video_texture/recon_5.png" alt="Image Steve" class="image" />
      </div>

      <!-- Video Module 1 -->
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos_jinzhi/video_texture/recon_5.mp4" type="video/mp4">
        </video>
      </div>

       <!-- Image Module 4 -->
       <div class="item item-steve">
        <img src="./static/videos_jinzhi/video_texture/recon_6.png" alt="Image Steve" class="image" />
      </div>

      <!-- Video Module 1 -->
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos_jinzhi/video_texture/recon_6.mp4" type="video/mp4">
        </video>
      </div>

       <!-- Image Module 4 -->
       <div class="item item-steve">
        <img src="./static/videos_jinzhi/video_texture/recon_7.png" alt="Image Steve" class="image" />
      </div>

      <!-- Video Module 1 -->
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos_jinzhi/video_texture/recon_7.mp4" type="video/mp4">
        </video>
      </div>
      
       <!-- Image Module 4 -->
       <div class="item item-steve">
        <img src="./static/videos_jinzhi/video_texture/recon_8.png" alt="Image Steve" class="image" />
      </div>

      <!-- Video Module 1 -->
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos_jinzhi/video_texture/recon_8.mp4" type="video/mp4">
        </video>
      </div>

      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX"></section>
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @misc{zhang20243drepresentation512bytevariationaltokenizer,
        title={3D representation in 512-Byte:Variational tokenizer is the key for autoregressive 3D generation}, 
        author={Jinzhi Zhang and Feng Xiong and Mu Xu},
        year={2024},
        eprint={2412.02202},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2412.02202}, 
  }
    </code></pre>
  </div>
</section>

  <script>
    function scrollCarousel(direction) {
      const container = document.getElementById('video-carousel');
      const videoItemWidth = 200; // Each video item's width
      const gap = 16; // The gap between items
      const scrollAmount = videoItemWidth + gap; // Total scroll amount

      container.scrollBy({ left: direction * scrollAmount, behavior: 'smooth' });
    }
  </script>

</body>
</html>
