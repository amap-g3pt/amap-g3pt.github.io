<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>VAT</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    

    /* Ensure teaser section is responsive */
    .teaser-image {
      width: 100%;
      height: auto;
    }
    .method-image-img-small {
  max-width: 80%;   /* 图片的最大宽度设为容器宽度的 80% */
  height: auto;     /* 保持图片的纵横比 */
  margin: 0 auto;   /* 居中显示 */
  display: block;   /* 使图片成为块级元素 */
}
.method-image-img-small-small {
  max-width: 50%;   /* 图片的最大宽度设为容器宽度的 80% */
  height: auto;     /* 保持图片的纵横比 */
  margin: 0 auto;   /* 居中显示 */
  display: block;   /* 使图片成为块级元素 */
}
  </style>
</head>
<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              G3PT: Unleash the Power of Autoregressive Modeling in 3D Generation via Cross-Scale Querying Transformer
            </h1>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.02202"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2412.02202"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <!-- Code Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/sparse-mvs-2/VAT"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span> -->
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="far fa-images"></i>
                    </span> -->
                    <!-- <span>Data</span> -->
                    </a>
              </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser"></section>
    <div class="container">
      <div class="hero-body">
        <img id="teaser-image" src="./static/images/Fig_pipeline.png" alt="Teaser Image" class="teaser-image">
        <p class="is-size-9" style="line-height: 1.6; color: #555;">
          <span class="dnerf" style="font-weight: bold; font-style: italic;">Overall pipeline of G3PT for representing and generating unordered 3D data.</span> 
          (a) Cross-scale Vector Quantization (CVQ): G3PT encodes the input point cloud into discrete scales of token vectors, 
          each representing a different level of detail. The proposed Cross-scale Querying Transformer (CQT) utilizes 
          cross-attention mechanisms with learnable queries of varying lengths to globally connect tokens across different scales, 
          without requiring the tokens to be organized in a specific order. The final output is the occupancy value for each query point. 
          (b) Cross-scale AutoRegressive modeling (CAR): G3PT reuses the CQT from the stage of CVQ for cross-scale dimension alignment and 
          enables scalable 3D native generation from coarse to fine scales under various conditions, 
          with an autoregressive transformer trained using next-scale prediction.
        </p>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Autoregressive transformers have revolutionized generative models in language processing and shown substantial promise in image and video generation. 
              However, these models face significant challenges when extended to 3D generation tasks due to their reliance on next-token prediction to learn token sequences, 
              which is incompatible with the unordered nature of 3D data. Instead of imposing an artificial order on 3D data, in this paper, 
              we introduce G3PT - a scalable, coarse-to-fine 3D native generative model with cross-scale vector quantization and 
              cross-scale autoregressive modeling. The key is to map point-based 3D data into discrete tokens with different levels of detail, 
              naturally establishing a sequential relationship across a variety of scales suitable for autoregressive modeling. 
              Remarkably, our method connects tokens globally across different levels of detail without manually specified ordering. 
              Benefiting from this approach, G3PT features a versatile 3D generation pipeline that effortlessly supports the generation of 
              3D shapes under diverse conditional modalities. Extensive experiments demonstrate that G3PT achieves superior 3D generation quality 
              and generalization ability compared to previous baselines. Most importantly, for the first time in 3D generation, 
              scaling up G3PT reveals distinct power-law scaling behaviors.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser"></section>
    <div class="container">
      <div class="hero-body">
        <p class="is-size-9" style="line-height: 1.6; color: #555;">
          <span class="dnerf" style="font-weight: bold; font-style: italic;">Abstract:</span> Autoregressive transformers have revolutionized generative models 
          in language processing and shown substantial promise in image and video generation. However, these models face significant challenges 
          when extended to 3D generation tasks due to their reliance on next-token prediction to learn token sequences, which is incompatible 
          with the unordered nature of 3D data. Instead of imposing an artificial order on 3D data, in this paper, 
          we introduce G3PT -- a scalable, coarse-to-fine 3D native generative model with cross-scale vector quantization and 
          cross-scale autoregressive modeling. The key is to map point-based 3D data into discrete tokens with different levels of detail, 
          naturally establishing a sequential relationship across a variety of scales suitable for autoregressive modeling. 
          Remarkably, our method connects tokens globally across different levels of detail without manually specified ordering. 
          Benefiting from this approach, G3PT features a versatile 3D generation pipeline that effortlessly supports the generation of 
          3D shapes under diverse conditional modalities. Extensive experiments demonstrate that G3PT achieves superior 3D generation quality 
          and generalization ability compared to previous baselines. Most importantly, for the first time in 3D generation, 
          scaling up G3PT reveals distinct power-law scaling behaviors.
        </p>
      </div>
    </div>
  </section> -->

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered">Comparison of multi-scale vector quantization approaches</h2>
          <image src="./static/images/Fig_CVQ.png" width=100% style="display: block; margin: auto;"></image>
          <div class="content has-text-justified">
            <p>
              (a) The quantization approach used in VAR relies on average pooling and bilinear upsampling, 
              which are not suitable for unordered data. (b) Our Cross-scale Vector Quantization (CVQ) overcomes this limitation with CQT, which employs a set of cross-scale learnable 
              queries to globally "downsample" and "upsample" the unordered input feature with cross-attention. 
              Specifically, a set of "downsample" learnable queries "pool" the input feature into token vectors of decreased length 
              at each scale, effectively forming a level-of-detail tokenization. These cross-scale token vectors are then "upsampled" 
              to the original scale for residual quantization, with another set of "upsample" learnable queries. 
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3 has-text-centered">Illustration of the proposed CAR process in G3PT</h2>
          <image src="./static/images/Fig_CAR.png" width=100% style="display: block; margin: auto;"></image>
          <div class="content has-text-justified">
            <p>
              The transformer predicts the next-scale token vector using features derived from the "upsampled" tokens of the previous scale. 
              The "upsampling" process involves two layers of cross-attention to align the number of tokens across scales. 
              First, features are "upsampled" with a learnable query, and then "downsampled" using another query to match the token number 
              of the next scale. A causal mask is applied to maintain the correct order and dependencies across different scales and 
              input conditions, ensuring coherence in the model predictions.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
 
  <!-- <section class="hero teaser">
    <div class="container">
      <div class="hero-body">
        <img id="teaser-image" src="./static/images/Fig_CVQ.png" alt="Teaser Image" class="teaser-image">
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Comparison of multi-scale vector quantization approaches.</span> (a) The quantization approach used in VAR 
          relies on average pooling and bilinear upsampling, which are not suitable for unordered data. 
          (b) Our Cross-scale Vector Quantization (CVQ) overcomes this limitation with CQT, which employs a set of cross-scale learnable 
          queries to globally "downsample" and "upsample" the unordered input feature with cross-attention. 
          Specifically, a set of "downsample" learnable queries "pool" the input feature into token vectors of decreased length 
          at each scale, effectively forming a level-of-detail tokenization. These cross-scale token vectors are then "upsampled" 
          to the original scale for residual quantization, with another set of "upsample" learnable queries. 
        </h2>
      </div>
    </div>
  </section> -->

  <!-- <section class="hero teaser">
    <div class="container">
      <div class="hero-body">
        <img id="teaser-image" src="./static/images/Fig_CAR.png" alt="Teaser Image" class="teaser-image">
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">Illustration of the proposed CAR process in G3PT.</span> The transformer predicts the 
          next-scale token vector using features derived from the "upsampled" tokens of the previous scale. 
          The "upsampling" process involves two layers of cross-attention to align the number of tokens across scales. 
          First, features are "upsampled" with a learnable query, and then "downsampled" using another query to match the token number 
          of the next scale. A causal mask is applied to maintain the correct order and dependencies across different scales and 
          input conditions, ensuring coherence in the model predictions.
        </h2>
      </div>
    </div>
  </section> -->


<section class="hero teaser">
  <div class="hero-body">
    <div class="container">
      <div class="method-module">
        
        <h2 class="title is-3 method-title" style="text-align: center;">Scaling law with network parameters N </h2>
        <!-- Image Section -->
        <div class="method-image">
          <img src="./static/images/Fig_scaling.png" alt="Methodology Image" class="method-image-img-small-small">
        </div>
        
        <h2 class="title is-2 method-title" style="text-align: center;"> </h2>
        

        <h2 class="title is-2 method-title" style="text-align: center;">3D Generation Comparision</h2>

        <!-- Image Section -->
        <div class="method-image">
          <img src="./static/images/fig_wild_compare.jpg" alt="Methodology Image" class="method-image-img">
        </div>

        <!-- Text Section -->
        <div class="method-description">
          <p class="is-size-9" style="margin-bottom: 40px;">
            Comparision of state-of-the art 3D generation methods using in-the-wild images. Note that the commercial software displayed on the left may expand thousands of their own data for training, whereas our model is only trained on the Objaverse dataset.
          </p>
        </div>
        
        <div class="method-description"></div>
          <p class="is-size-9">
            
          </p>
        </div>
        <div class="method-image">
          <img src="./static/images/table_gen.png" alt="Methodology Image" class="method-image-img-small">
        </div>

        <!-- Text Section -->
        <div class="method-description">
          <p class="is-size-9" style="text-align: center;">
            Quantitative comparison of state-of-the-art 3D generation methods.
          </p>
          
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="hero-body">
    <div class="container">
      <div class="method-module">
        <h2 class="title is-2 method-title" style="text-align: center;"> </h2>

        <h2 class="title is-2 method-title" style="text-align: center;">Necessity of VVQ</h2>

        <!-- Image Section -->
        <div class="method-image">
          <img src="./static/images/compare_tab.png" alt="Methodology Image" class="method-image-img-small-small">
        </div>

        <!-- Text Section -->
        <div class="method-description" style="margin-bottom: 40px;">
          <p class="is-size-9">
            Reconstruction results with varying numbers of tokens, with and without in-context token compression (Comp.) and Variational Vector Quantization (VVQ).
            By incorporating VVQ, our VAT achieves the best balance between reconstruction accuracy and cross-scale consistency.
          </p>
        </div>
        
        <div class="method-description"></div>
          <p class="is-size-9">
            
          </p>
        </div>
        <div class="method-image">
          <img src="./static/images/fig_supp_multiscale.jpg" alt="Methodology Image" class="method-image-img">
        </div>

        <!-- Text Section -->
        <div class="method-description">
          <p class="is-size-9" style="text-align: center;">
            Visualization of reconstructed mesh from different scales of tokens, with and without VVQ.
          </p>
          
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
     
      <h1 class="title is-3 publication-title">
        512-Byte code can represent delicated geometry (2000× compression):
      </h1>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_0.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_1.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_5.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_6.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_8.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_9.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_10.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_11.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_13.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_14.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_15.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_16.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_17.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_recon/recon_18.mp4"
                    type="video/mp4">
          </video>
        </div>
        
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <h1 class="title is-3 publication-title">
        Results of 3D generation conditioned on images:
      </h1>
      <!-- Carousel Container with Image and Video Modules -->
      <div id="results-carousel" class="carousel results-carousel">
        
        <!-- Image Module 1 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_0.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_0.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 2 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_1.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_1.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 3 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_2.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_2.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 4 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_3.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_3.mp4" type="video/mp4">
          </video>
        </div>

         <!-- Image Module 4 -->
         <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_4.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_4.mp4" type="video/mp4">
          </video>
        </div>

      
        
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">

      <!-- Carousel Container with Image and Video Modules -->
      <div id="results-carousel" class="carousel results-carousel">
        
        <!-- Image Module 1 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_7.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_7.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 2 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_8.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_8.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 3 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_9.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_9.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 4 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_6.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_6.mp4" type="video/mp4">
          </video>
        </div>

         <!-- Image Module 4 -->
         <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_gen/recon_5.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_gen/recon_5.mp4" type="video/mp4">
          </video>
        </div>

      
        
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small"></section>
  <div class="hero-body">
    <div class="container">
      <h1 class="title is-3 publication-title">
        Mesh visualization with generated textures:
      </h1>
      <!-- Carousel Container with Image and Video Modules -->
      <div id="results-carousel" class="carousel results-carousel">
        
        <!-- Image Module 1 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_texture/recon_0.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_texture/recon_0.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 2 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_texture/recon_2.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_texture/recon_2.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 3 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_texture/recon_3.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_texture/recon_3.mp4" type="video/mp4">
          </video>
        </div>

        <!-- Image Module 4 -->
        <div class="item item-steve">
          <img src="./static/videos_jinzhi/video_texture/recon_4.png" alt="Image Steve" class="image" />
        </div>

        <!-- Video Module 1 -->
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos_jinzhi/video_texture/recon_4.mp4" type="video/mp4">
          </video>
        </div>


       <!-- Image Module 4 -->
       <div class="item item-steve">
        <img src="./static/videos_jinzhi/video_texture/recon_5.png" alt="Image Steve" class="image" />
      </div>

      <!-- Video Module 1 -->
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos_jinzhi/video_texture/recon_5.mp4" type="video/mp4">
        </video>
      </div>

       <!-- Image Module 4 -->
       <div class="item item-steve">
        <img src="./static/videos_jinzhi/video_texture/recon_6.png" alt="Image Steve" class="image" />
      </div>

      <!-- Video Module 1 -->
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos_jinzhi/video_texture/recon_6.mp4" type="video/mp4">
        </video>
      </div>

       <!-- Image Module 4 -->
       <div class="item item-steve">
        <img src="./static/videos_jinzhi/video_texture/recon_7.png" alt="Image Steve" class="image" />
      </div>

      <!-- Video Module 1 -->
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos_jinzhi/video_texture/recon_7.mp4" type="video/mp4">
        </video>
      </div>
      
       <!-- Image Module 4 -->
       <div class="item item-steve">
        <img src="./static/videos_jinzhi/video_texture/recon_8.png" alt="Image Steve" class="image" />
      </div>

      <!-- Video Module 1 -->
      <div class="item item-chair-tp">
        <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos_jinzhi/video_texture/recon_8.mp4" type="video/mp4">
        </video>
      </div>

      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX"></section>
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @misc{zhang20243drepresentation512bytevariationaltokenizer,
        title={3D representation in 512-Byte:Variational tokenizer is the key for autoregressive 3D generation}, 
        author={Jinzhi Zhang and Feng Xiong and Mu Xu},
        year={2024},
        eprint={2412.02202},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2412.02202}, 
  }
    </code></pre>
  </div>
</section>

  <script>
    function scrollCarousel(direction) {
      const container = document.getElementById('video-carousel');
      const videoItemWidth = 200; // Each video item's width
      const gap = 16; // The gap between items
      const scrollAmount = videoItemWidth + gap; // Total scroll amount

      container.scrollBy({ left: direction * scrollAmount, behavior: 'smooth' });
    }
  </script>

</body>
</html>
